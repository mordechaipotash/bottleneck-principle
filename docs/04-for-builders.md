# For Builders

How to implement the Bottleneck Principle in your own work.

---

## The Core Question

Before you build anything, ask:

> "Where is the human sovereignty point in this system?"

Not "how do we automate this?" but "where does the human decide?"

---

## Implementation Principles

### 1. Identify Your Phase 3

> "The natural and inevitable bottleneck by definition is the ability of AI to 'download' the data to the human so he understands enough to have 100% agency."
>
> *— August 2025 | Claude Code*

Every system has a compression point where infinite options become human-scale choices. Find it. Protect it. Optimize it.

**Questions to ask:**
- Where does the human make the final decision?
- How many options are they choosing from?
- Can they understand each option with confidence?

---

### 2. Compress to 2-5, Not 1000

> "AI can help me 100x but just like the gap between AI tech and AI adoption is miles away and I am obsessed with UI making things simple... this is my main prosthetic."
>
> *— August 2025 | Claude Code*

**The compression ratio matters:**
- 10,000 options → human paralysis
- 2-5 options → human agency
- 1 option → no human agency (AI decided for them)

**Implementation:**
```
Input:  Thousands of possibilities
AI:     Analyze, rank, filter
Output: 2-5 clear options with reasoning
Human:  Decides with confidence
```

---

### 3. Audit Trail Everything

> "One human decision. Infinite AI execution. With proofs."
>
> *— September 2025 | Claude Code*

Every AI action should trace back to a human decision.

**Requirements:**
- Log every human decision point
- Document AI reasoning at each step
- Make reversal possible at any point
- Human can audit any step at any time

---

### 4. Translation Over Intelligence

> "The solution isn't smarter AI. It's better translation."
>
> *— January 2026 | Reddit*

Stop trying to make AI smarter. Start making the human-AI interface clearer.

**Bad approach:**
- "Let's add more AI capabilities"
- "Let's make the AI more autonomous"
- "Let's reduce human involvement"

**Good approach:**
- "Let's make options clearer"
- "Let's improve explanation quality"
- "Let's increase human confidence"

---

## Anti-Patterns

### Don't: Eliminate the Bottleneck

> "The bottleneck is the human-AI interface. Always was. Always will be. And that bottleneck is a feature, not a bug. It's what keeps humans sovereign."
>
> *— December 2025 | Claude Code*

The temptation: "Let's remove human decision points to go faster."

The reality: You're removing sovereignty, not friction.

### Don't: Automate Decisions

> "It is the responsibility of the person who controls or has agency over their AI, whatever the AI does. And therefore no matter how good AI gets, it's always going to need the human trigger always."
>
> *— May 2025 | Claude Code*

If AI makes the decision, the human loses responsibility. And responsibility is sovereignty.

### Don't: Optimize for Speed Over Understanding

> "Only as fast as AI can explain to us and AI can empower us to decide with confidence."
>
> *— September 2025 | Claude Code*

Speed without understanding is just faster confusion.

---

## Reference Implementation: Brain MCP

The framework was built from a working system:

```
CAPTURE:   3 years of life → digital artifacts
           - 353K conversation messages
           - 31K YouTube videos
           - 132 GitHub repos
           - 52K Google searches

COMPRESS:  Raw data → patterns
           - 106K embedded messages
           - 973 knowledge graph nodes
           - 8 SEED principles
           - Signature phrases extracted

CHOOSE:    Query → 2-5 options
           - "Who should I contact?"
           - AI processes 353K messages
           - Returns 3 ranked people with reasoning
           - Human chooses

EXECUTE:   Decision → action
           - Draft message
           - Research context
           - Track follow-up
           - Full audit trail
```

---

## Quick Implementation Checklist

- [ ] Identified the human sovereignty point (Phase 3)
- [ ] Compression outputs 2-5 options, not more
- [ ] Each option includes reasoning
- [ ] Human can understand each option with confidence
- [ ] Every AI action has audit trail
- [ ] Decisions are reversible
- [ ] Speed is limited by human understanding, not AI capability

---

## The Test

Ask yourself: "If this system makes a mistake, who is responsible?"

If the answer isn't clear, you've eliminated too much human sovereignty.

If the answer is "the AI," you've built the wrong system.

If the answer is "the human who made the decision," you've built it right.

---

*From the Bottleneck Principle Framework | 2023-2026*
